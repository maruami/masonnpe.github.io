<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Collections.sort()解读]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FCollections.sort()%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[Collections.sort方法底层就是调用的Array.sort 123456789101112131415161718192021222324252627282930313233343536373839404142434445static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // array的大小为0或者1就不用排了 // 当数组大小小于MIN_MERGE(32)的时候，就用一个"mini-TimSort"的方法排序 if (nRemaining &lt; MIN_MERGE) &#123; // 将最长的递减序列，找出来，然后倒过来 int initRunLen = countRunAndMakeAscending(a, lo, hi, c); // 长度小于32的时候，是使用binarySort的 binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; // 先扫描一次array，找到已经排好的序列，然后再用刚才的mini-TimSort，然后合并 TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Collections</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ApplicationContext]]></title>
    <url>%2F2018%2F11%2F03%2FSpring%2FApplicationContext%2F</url>
    <content type="text"><![CDATA[applicationcontext和beanfactory都是加载bean的 applicationcontext包含beanfactory的所有功能，是对beanfactory的扩展。 添加了@Qualifier @Autowired等功能 beanfactory适合内存小的 实例化bean比较复杂，FactoryBean是一个工厂类接口，可以通过改接口实例化bean的逻辑 spring中的循环依赖分三种 构造器循环依赖 无法解决 只能跑出beancurrentlyincreateionexception setter注入 通过提前暴露单例工厂方法addSingletionFactory protootype,spring无法完成依赖注入]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>ApplicationContext</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[001两数之和]]></title>
    <url>%2F2018%2F11%2F03%2FLeetCode%2F001%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%20%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122public class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = i+1; j &lt; nums.length; j++) &#123; if(nums[j]==target-nums[i]) &#123; return new int[] &#123;i,j&#125;; &#125; &#125; &#125; throw new IllegalArgumentException("No two sum solution"); &#125; public static void main(String[] args) &#123; Solution solution=new Solution(); int[] nums= &#123;2, 7, 11, 15&#125;; int target=9; int[] data= solution.twoSum(nums, target); System.out.println(Arrays.toString(data)); &#125;&#125; 1234567891011121314151617181920212223242526public class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map=new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i], i); &#125; for (int i = 0; i &lt; nums.length; i++) &#123; int key=target-nums[i]; if(map.containsKey(key)&amp;&amp;map.get(key)!=i) &#123; return new int[] &#123;i,map.get(key)&#125;; &#125; &#125; throw new IllegalArgumentException("No two sum solution"); &#125; public static void main(String[] args) &#123; Solution solution=new Solution(); int[] nums= &#123;2, 7, 11, 15&#125;; int target=9; int[] data= solution.twoSum(nums, target); System.out.println(Arrays.toString(data)); &#125;&#125; 1234567891011121314151617181920212223public class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map=new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i], i); int key=target-nums[i]; if(map.containsKey(key)&amp;&amp;map.get(key)!=i) &#123; return new int[] &#123;map.get(key),i&#125;; &#125; &#125; throw new IllegalArgumentException(&quot;No two sum solution&quot;); &#125; public static void main(String[] args) &#123; Solution solution=new Solution(); int[] nums= &#123;2, 7, 11, 15&#125;; int target=9; int[] data= solution.twoSum(nums, target); System.out.println(Arrays.toString(data)); &#125;&#125; 总结：检查数组中是否存在目标元素，返回下标，保持数组中的每个元素与其索引相互对应的最好方法是哈希表]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Queue]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FQueue%2F</url>
    <content type="text"><![CDATA[method description add 添加元素 如果队列满 抛出异常 offer 元素插入到队尾 如果队列满，返回false put 添加元素 队列满则阻塞 peek 不移除元素返回队头，队列为空返回null element 不移除元素返回队头，队列为空抛异常 poll 移除元素返回队头，队列为空返回null remove 移除元素返回队头，队列为空抛异常 take 移除并返回队头，队列空则阻塞]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Queue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[数组初始化123int[] arr1= new int[5];int[] arr2= &#123;1,2,3,4,5&#125;;int[] arr3= new int[] &#123;1,2,3,4,5&#125;; Arrays method description Arrays.fill(arr, val); 替换数组的值 Arrays.fill(arr, fromIndex, toIndex, val); 替换数组下标[fromIndex,toIndex)的值 Arrays.copyOf(arr, newLength); 拷贝数组，先数组长度为newLength Arrays.copyOfRange(arr, from, to); 拷贝数组下标[from,to)的值 Arrays.toString(arr); 打印数组 Arrays.binarySearch(arr, val); 二分查找，返回下标 System.arraycopy(src, srcPos, dest, destPos, length); src原数组，srcPos起始index，dest目标数组，despos起始位置，length拷贝长度，属于浅拷贝 Arrays.sort(arr); 排序 Arrays.equals(arr1, arr2); 比较两个数据是否相等]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[简单的JDBC]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2F%E7%AE%80%E5%8D%95%E7%9A%84JDBC%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536public class Conn &#123; static Connection connection; static Statement stat; static ResultSet rs; public Connection getConnection() &#123; try &#123; Class.forName(&quot;com.mysql.jdbc.Driver&quot;); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; Connection conn=null; try &#123; conn=DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/mall&quot;, &quot;root&quot;, &quot;Gepoint&quot;); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn; &#125; public static void main(String[] args) &#123; Conn c=new Conn(); connection=c.getConnection(); try &#123; stat=connection.createStatement(); rs=stat.executeQuery(&quot;select * from spbrands limit 10&quot;); while(rs.next()) &#123; String brand=rs.getString(&quot;Brand&quot;); System.out.println(&quot;品牌:&quot;+brand); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap实现一个LRU本地缓存]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FLinkedHashMap%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AALRU%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[基于访问的最近最少使用算法 构造函数accessOrder=true时,当get（Object key）时，将最新访问的元素放到双向链表的第一位 123456789101112131415161718192021222324252627public class Demo &#123; public static void main(String[] args) &#123; Map&lt;String,String&gt; map=new LinkedHashMap&lt;&gt;(16,0.75f,true); map.put(&quot;brand1&quot;, &quot;12&quot;); map.put(&quot;brand2&quot;, &quot;13&quot;); map.put(&quot;brand3&quot;, &quot;14&quot;); map.put(&quot;brand4&quot;, &quot;15&quot;); map.put(&quot;brand5&quot;, &quot;16&quot;); map.put(&quot;brand6&quot;, &quot;17&quot;); print(map); map.get(&quot;brand2&quot;); print(map); map.get(&quot;brand5&quot;); print(map); &#125; private static void print(Map&lt;String,String&gt; map) &#123; Set&lt;Entry&lt;String,String&gt;&gt; set=map.entrySet(); Iterator&lt;Entry&lt;String,String&gt;&gt; i=set.iterator(); while(i.hasNext()) &#123; Entry&lt;String,String&gt; entry=i.next(); System.out.println(entry.getValue()+entry.getKey()); &#125; System.out.println(&quot;---&quot;); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String与StrinBuilder与StringBuffer]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FString%E4%B8%8EStrinBuilder%E4%B8%8EStringBuffer%2F</url>
    <content type="text"><![CDATA[StringString的创建机理由于String在Java世界中使用过于频繁，Java为了避免在一个系统中产生大量的String对象，引入了字符串常量池。其运行机制是： 创建一个字符串时，首先检查池中是否有值相同的字符串对象，如果有则不需要创建直接从池中刚查找到的对象引用；如果没有则新建字符串对象，返回对象引用，并且将新创建的对象放入池中。但是，通过new方法创建的String对象是不检查字符串池的，而是直接在堆区或栈区创建一个新的对象，也不会把对象放入池中。上述原则只适用于通过直接量给String对象引用赋值的情况。 举例： 12String str1 = "123"; //通过直接量赋值方式，放入字符串常量池String str2 = new String(“123”);//通过new方式赋值方式，不放入字符串常量池 注意：String提供了intern()方法。调用该方法时，如果常量池中包括了一个等于此String对象的字符串（由equals方法确定），则返回池中的字符串。否则，将此String对象添加到池中，并且返回此池中对象的引用。 Intern()是一种显式地排重机制，但是它也有一定的副作用，因为需要开发者写代码时明确调用，一是不方便，每一个都显式调用是非常麻烦的；另外就是我们很难保证效率，应用开发阶段很难清楚地预计字符串的重复情况，有人认为这是一种污染代码的实践。幸好在Oracle JDK 8u20之后，推出了一个新的特性，也就是G1 GC下的字符串排重。它是通过将相同数据的字符串指向同一份数据来做到的，是JVM底层的改变，并不需要Java类库做什么修改。注意这个功能目前是默认关闭的，你需要使用下面参数开启，并且记得指定使用G1 GC：-XX:+UseStringDeduplication String的特性 不可变。是指String对象一旦生成，则不能再对它进行改变。不可变的主要作用在于当一个对象需要被多线程共享，并且访问频繁时，可以省略同步和锁等待的时间，从而大幅度提高系统性能。不可变模式是一个可以提高多线程程序的性能，降低多线程程序复杂度的设计模式。 针对常量池的优化。当2个String对象拥有相同的值时，他们只引用常量池中的同一个拷贝。当同一个字符串反复出现时，这个技术可以大幅度节省内存空间。 StringBufer/StringBuilderStringBuffer和StringBuilder都实现了AbstractStringBuilder抽象类，拥有几乎一致对外提供的调用接口；其底层在内存中的存储方式与String相同，都是以一个有序的字符序列（char类型的数组）进行存储，不同点是StringBufer/StringBuilder对象的值是可以改变的，并且值改变以后，对象引用不会发生改变;两者对象在构造过程中，首先按照默认大小申请一个字符数组，由于会不断加入新数据，当超过默认大小后，会创建一个更大的数组，并将原先的数组内容复制过来，再丢弃旧的数组。因此，对于较大对象的扩容会涉及大量的内存复制操作，如果能够预先评估大小，可提升性能。需要注意的是：StringBuffer是线程安全的，但是StringBuilder是线程不安全的，StringBuffer类中方法定义前面都会有synchronized关键字。为此，StringBuffer的性能要远低StringBuilder 应用场景 在字符串内容不经常发生变化的业务场景优先使用String类。例如：常量声明、少量的字符串拼接操作等。如果有大量的字符串内容拼接，避免使用String与String之间的“+”操作，因为这样会产生大量无用的中间对象，耗费空间且执行效率低下（新建对象、回收对象花费大量时间）。 在频繁进行字符串的运算（如拼接、替换、删除等），并且运行在多线程环境下，建议使用StringBufer，例如XML解析、HTTP参数解析与封装。 在频繁进行字符串的运算（如拼接、替换、删除等），并且运行在单线程环境下，建议使用StringBuilder，例如SQL语句拼装、JSON封装等。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行数组]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2F%E5%B9%B6%E8%A1%8C%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[并行数组Java8版本新增了很多新的方法，用于支持并行数组处理。最重要的方法是parallelSort()，可以显著加快多核机器上的数组排序。下面的例子论证了parallexXxx系列的方法： 123456789101112131415161718192021package com.javacodegeeks.java8.parallel.arrays;import java.util.Arrays;import java.util.concurrent.ThreadLocalRandom;public class ParallelArrays &#123; public static void main( String[] args ) &#123; long[] arrayOfLong = new long [ 20000 ]; Arrays.parallelSetAll( arrayOfLong, index -&gt; ThreadLocalRandom.current().nextInt( 1000000 ) ); Arrays.stream( arrayOfLong ).limit( 10 ).forEach( i -&gt; System.out.print( i + " " ) ); System.out.println(); Arrays.parallelSort( arrayOfLong ); Arrays.stream( arrayOfLong ).limit( 10 ).forEach( i -&gt; System.out.print( i + " " ) ); System.out.println(); &#125;&#125; 上述这些代码使用parallelSetAll()方法生成20000个随机数，然后使用parallelSort()方法进行排序。这个程序会输出乱序数组和排序数组的前10个元素。上述例子的代码输出的结果是： 12Unsorted: 591217 891976 443951 424479 766825 351964 242997 642839 119108 552378 Sorted: 39 220 263 268 325 607 655 678 723 793]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[接口的默认方法和静态方法]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2F%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%BB%98%E8%AE%A4%E6%96%B9%E6%B3%95%E5%92%8C%E9%9D%99%E6%80%81%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[接口的默认方法和静态方法Java 8使用两个新概念扩展了接口的含义：默认方法和静态方法。 默认方法默认方法使得开发者可以在 不破坏二进制兼容性的前提下，往现存接口中添加新的方法，即不强制那些实现了该接口的类也同时实现这个新加的方法。 默认方法和抽象方法之间的区别在于抽象方法需要实现，而默认方法不需要。接口提供的默认方法会被接口的实现类继承或者覆写，例子代码如下： 1234567891011121314151617private interface Defaulable &#123; // Interfaces now allow default methods, the implementer may or // may not implement (override) them. default String notRequired() &#123; return "Default implementation"; &#125; &#125;private static class DefaultableImpl implements Defaulable &#123;&#125;private static class OverridableImpl implements Defaulable &#123; @Override public String notRequired() &#123; return "Overridden implementation"; &#125;&#125; Defaulable接口使用关键字default定义了一个默认方法notRequired()。DefaultableImpl类实现了这个接口，同时默认继承了这个接口中的默认方法；OverridableImpl类也实现了这个接口，但覆写了该接口的默认方法，并提供了一个不同的实现。 静态方法Java 8带来的另一个有趣的特性是在接口中可以定义静态方法，我们可以直接用接口调用这些静态方法。例子代码如下： 123456private interface DefaulableFactory &#123; // Interfaces now allow static methods static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123; return supplier.get(); &#125;&#125; 下面的代码片段整合了默认方法和静态方法的使用场景： 12345678public static void main( String[] args ) &#123; // 调用接口的静态方法，并且传递DefaultableImpl的构造函数引用来构建对象 Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new ); System.out.println( defaulable.notRequired() ); // 调用接口的静态方法，并且传递OverridableImpl的构造函数引用来构建对象 defaulable = DefaulableFactory.create( OverridableImpl::new ); System.out.println( defaulable.notRequired() );&#125; 这段代码的输出结果如下： 12Default implementationOverridden implementation 由于JVM上的默认方法的实现在字节码层面提供了支持，因此效率非常高。默认方法允许在不打破现有继承体系的基础上改进接口。该特性在官方库中的应用是：给java.util.Collection接口添加新方法，如stream()、parallelStream()、forEach()和removeIf()等等。 尽管默认方法有这么多好处，但在实际开发中应该谨慎使用：在复杂的继承体系中，默认方法可能引起歧义和编译错误。如果你想了解更多细节，可以参考官方文档。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Optional]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FOptional%2F</url>
    <content type="text"><![CDATA[OptionalJava应用中最常见的bug就是空指针异常 Optional仅仅是一个容器，可以存放T类型的值或者null。它提供了一些有用的接口来避免显式的null检查，可以参考Java 8官方文档了解更多细节。 method description isPresent 有值返回true 否则返回false get() 有值时返回值 没有抛出异常 orElse 有值时返回值 没有返回默认值 orElseGet 有值时返回值 没有返回一个supplier接口生成的值 map 只存在就执行mapping函数调用,以将现有Optional实例的值转换成新的值 创建Optional1234567Apple apple = new Apple();// 空的optionalOptional&lt;Apple&gt; optApple=Optional.empty(); // 值为nul抛出异常Optional&lt;Apple&gt; optApple1=Optional.of(apple); // 值为null 返回空的optionalOptional&lt;Apple&gt; optApple2=Optional.ofNullable(apple);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Optional</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM故障引起的问题]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2FJVM%E6%95%85%E9%9A%9C%E5%BC%95%E8%B5%B7%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[nio操作用到堆外内存，堆外内存只能等老年代满了以后fullgc 顺便回收一下，否则会一直等到oom 异步处理 等待的线程太多 积压了很多socket，jvm直接崩溃，所有改成生产者消费者的模式]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM性能监控和故障处理工具]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2FJVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%92%8C%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[jps查看虚拟机进程状态 -l 主类的全名 -v 数据jvm参数 jstat看虚拟机状态 jstat -gc 6424 jstat -gcutil 6424 jinfo 看jvm的参数 jinfo -flag CMSInitiatingOccupancyFraction 5192 jmap -dump:format=b,file=D:\DUMP.bin 5192 生成堆转储快照 jmap -heap 5192 堆详情信息 jhat D:\DUMP.bin 分析dump jstack 5192 打印堆栈信息 jconsole、visualVM可视化工具]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[引用类型]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2F%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[判定对象是否可被回收都与引用有关，在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 引用类型强引用1Object obj = new Object(); 通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出OutOfMemoryError运行时错误（OOM）使程序异常终止，也不会随意回收具有强引用的“存活”对象来解决内存不足的问题。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 软引用123Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; 软引用通过SoftReference类实现。 软引用的生命周期比强引用短一些。只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即JVM 会确保在抛出 OutOfMemoryError之前，清理软引用指向的对象。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null,否则该方法返回队列中前面的一个Reference对象。应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 android图片缓存框架中，“内存缓存”中的图片是以这种引用来保存，使得JVM在发生OOM之前，可以回收这部分缓存 弱引用123Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null; 弱引用通过WeakReference类实现。 弱引用的生命周期比软引用短。被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。应用场景：弱应用同样可用于内存敏感的缓存。 在静态内部类中，经常会使用虚引用。例如，一个类发送网络请求，承担callback的静态内部类，则常以虚引用的方式来保存外部类(宿主类)的引用，当外部类需要被JVM回收时，不会因为网络请求没有及时回来，导致外部类不能被回收，引起内存泄漏 虚引用123Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj);obj = null; 特点：虚引用也叫幻象引用，通过PhantomReference类来实现。无法通过虚引用访问对象的任何属性或函数。幻象引用仅仅是提供了一种确保对象被 fnalize 以后，做某些事情的机制。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue);程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 这种引用的get()方法返回总是null，所以，可以想象，在平常的项目开发肯定用的少。但是根据这种引用的特点，我想可以通过监控这类引用，来进行一些垃圾清理的动作 引用队列引用队列（ReferenceQueue）使用谈到各种引用的编程，就必然要提到引用队列。我们在创建各种引用并关联到响应对象时，可以选择是否需要关联引用队列，JVM会在特定时机将引用enqueue到队列里，我们可以从队列里获取引用（remove方法在这里实际是有获取的意思）进行相关后续逻辑。尤其是幻象引用，get方法只返回null，如果再不指定引用队列，基本就没有意义了。看看下面的示例代码。利用引用队列，我们可以在对象处于相应状态时（对于幻象引用，就是前面说的被fnalize了，处于幻象可达状态），执行后期处理逻辑。 1234567891011121314Object counter = new Object();ReferenceQueue refQueue = new ReferenceQueue&lt;&gt;();PhantomReference&lt;Object&gt; p = new PhantomReference&lt;&gt;(counter, refQueue);counter = null;Sysem.gc();try &#123; // Remove是一个阻塞方法，可以指定timeout，或者选择一直阻塞 Reference&lt;Object&gt; ref = refQueue.remove(1000L); if (ref != null) &#123; // do something &#125;&#125; catch (InterruptedException e) &#123; // Handle it&#125;]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Reference</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM参数]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2FJVM%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Java HotSpot VM Options文档官网的这份文档有点老了不知道新的在哪儿，可以做参考 内存和GC-XX:MaxDirectMemorySize 堆外内存的最大值 -XX:MetaspaceSize=128m Metaspace初始大小 第一次扩张会造成JVM停顿，spring aop后类比较多 -XX:MaxMetaspaceSize=512m Metaspace最大大小 设一个更大的Max值以求保险，防止将内存用光 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly 内存达到75%主动CMS GC -XX:+ExplicitGCInvokesConcurrent 让full gc时使用CMS算法，不是全程停顿 性能 -XX:AutoBoxCacheMax=20000 加大Integer Cache 自动装箱时缓冲中有的直接从缓存拿 运维-Xloggc:/dev/shm/gc-myapp.log -XX:+PrintGCDateStamps -XX:+PrintGCDetails 打印gc日志 -XX:+PrintCommandLineFlags 将每次启动的参数输出到stdout -XX:-OmitStackTraceInFastThrow 输出完整栈的日志 -XX:ErrorFile =${LOGDIR}/hs_err_%p.log JVM crash时，hotspot 会生成一个error文件，提供JVM状态信息的细节。如前所述，将其输出到固定目录，避免到时会到处找这文件。文件名中的%p会被自动替换为应用的PID -XX:+HeapDumpOnOutOfMemoryError 在OOM时，输出一个dump.core文件，记录当时的堆内存快照 对内存快照目录设置-XX:HeapDumpPath=${LOGDIR}/ -XX:+PrintGCApplicationStoppedTime 打印清晰的完整的GC停顿时间外，还可以打印其他的JVM停顿时间，比如取消偏向锁，class 被agent redefine，code deoptimization等等 -XX:+PrintPromotionFailure 多大的新生代对象晋升到老生代失败从而引发Full GC的 -XX:+PrintSafepointStatistics -XX:PrintSafepointStatisticsCount=1 -XX:+UnlockDiagnosticVMOptions -XX:-DisplayVMOutput -XX:+LogVMOutput -XX:LogFile=/dev/shm/vm-myapp.log 开启安全点日志 Option and Default Value Description -Xms 初始堆大小 -Xmx 最大堆大小 -Xss 线程占用栈空间大小，默认1m（以前是256k），可以适当调小，节约空间开启更多的线程 -Xmn 新生代的大小 JDK默认新生代占堆大小的1/3，调大可以让对象尽量在新生代被回收掉，不进入老年代 Behavioral Options Option and Default Value Description -XX:-AllowUserSignalHandlers Do not complain if the application installs signal handlers. (Relevant to Solaris and Linux only.) -XX:AltStackSize=16384 Alternate signal stack size (in Kbytes). (Relevant to Solaris only, removed from 5.0.) -XX:-DisableExplicitGC By default calls to System.gc() are enabled (-XX:-DisableExplicitGC). Use -XX:+DisableExplicitGC to disable calls to System.gc(). Note that the JVM still performs garbage collection when necessary. -XX:+FailOverToOldVerifier Fail over to old verifier when the new type checker fails. (Introduced in 6.) -XX:+HandlePromotionFailure The youngest generation collection does not require a guarantee of full promotion of all live objects. (Introduced in 1.4.2 update 11) [5.0 and earlier: false.] -XX:+MaxFDLimit Bump the number of file descriptors to max. (Relevant to Solaris only.) -XX:PreBlockSpin=10 Spin count variable for use with -XX:+UseSpinning. Controls the maximum spin iterations allowed before entering operating system thread synchronization code. (Introduced in 1.4.2.) -XX:-RelaxAccessControlCheck Relax the access control checks in the verifier. (Introduced in 6.) -XX:+ScavengeBeforeFullGC Do young generation GC prior to a full GC. (Introduced in 1.4.1.) -XX:+UseAltSigs Use alternate signals instead of SIGUSR1 and SIGUSR2 for VM internal signals. (Introduced in 1.3.1 update 9, 1.4.1. Relevant to Solaris only.) -XX:+UseBoundThreads Bind user level threads to kernel threads. (Relevant to Solaris only.) -XX:-UseConcMarkSweepGC Use concurrent mark-sweep collection for the old generation. (Introduced in 1.4.1) -XX:+UseGCOverheadLimit Use a policy that limits the proportion of the VM’s time that is spent in GC before an OutOfMemory error is thrown. (Introduced in 6.) -XX:+UseLWPSynchronization Use LWP-based instead of thread based synchronization. (Introduced in 1.4.0. Relevant to Solaris only.) -XX:-UseParallelGC Use parallel garbage collection for scavenges. (Introduced in 1.4.1) -XX:-UseParallelOldGC Use parallel garbage collection for the full collections. Enabling this option automatically sets -XX:+UseParallelGC. (Introduced in 5.0 update 6.) -XX:-UseSerialGC Use serial garbage collection. (Introduced in 5.0.) -XX:-UseSpinning Enable naive spinning on Java monitor before entering operating system thread synchronizaton code. (Relevant to 1.4.2 and 5.0 only.) [1.4.2, multi-processor Windows platforms: true] -XX:+UseTLAB Use thread-local object allocation (Introduced in 1.4.0, known as UseTLE prior to that.) [1.4.2 and earlier, x86 or with -client: false] -XX:+UseSplitVerifier Use the new type checker with StackMapTable attributes. (Introduced in 5.0.)[5.0: false] -XX:+UseThreadPriorities Use native thread priorities. -XX:+UseVMInterruptibleIO Thread interrupt before or with EINTR for I/O operations results in OS_INTRPT. (Introduced in 6. Relevant to Solaris only.) Garbage First (G1) Garbage Collection Options Option and Default Value Description -XX:+UseG1GC Use the Garbage First (G1) Collector -XX:MaxGCPauseMillis=n Sets a target for the maximum GC pause time. This is a soft goal, and the JVM will make its best effort to achieve it. -XX:InitiatingHeapOccupancyPercent=n Percentage of the (entire) heap occupancy to start a concurrent GC cycle. It is used by GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap, not just one of the generations (e.g., G1). A value of 0 denotes ‘do constant GC cycles’. The default value is 45. -XX:NewRatio=n 老年代/新生代. 默认2. -XX:SurvivorRatio=n eden/survivor值. 默认8. -XX:MaxTenuringThreshold=n 对象在Survivor区最多熬过多少次Young GC后晋升到年老代，调大让对象在新生代多存活几次，默认15 -XX:ParallelGCThreads=n Sets the number of threads used during parallel phases of the garbage collectors. The default value varies with the platform on which the JVM is running. -XX:ConcGCThreads=n Number of threads concurrent garbage collectors will use. The default value varies with the platform on which the JVM is running. -XX:G1ReservePercent=n Sets the amount of heap that is reserved as a false ceiling to reduce the possibility of promotion failure. The default value is 10. -XX:G1HeapRegionSize=n With G1 the Java heap is subdivided into uniformly sized regions. This sets the size of the individual sub-divisions. The default value of this parameter is determined ergonomically based upon heap size. The minimum value is 1Mb and the maximum value is 32Mb. Performance Options Option and Default Value Description -XX:+AggressiveOpts Turn on point performance compiler optimizations that are expected to be default in upcoming releases. (Introduced in 5.0 update 6.) -XX:CompileThreshold=10000 Number of method invocations/branches before compiling [-client: 1,500] -XX:LargePageSizeInBytes=4m Sets the large page size used for the Java heap. (Introduced in 1.4.0 update 1.) [amd64: 2m.] -XX:MaxHeapFreeRatio=70 GC后，如果发现空闲堆内存大于70%时，则收缩堆内存的最大值 -XX:MaxNewSize=size Maximum size of new generation (in bytes). Since 1.4, MaxNewSize is computed as a function of NewRatio. [1.3.1 Sparc: 32m; 1.3.1 x86: 2.5m.] -XX:MinHeapFreeRatio=40 GC后，如果发现空闲堆内存小于40%时，则放大堆内存的最大值，但不超过固定最大值 -XX:NewRatio=2 Ratio of old/new generation sizes. [Sparc -client: 8; x86 -server: 8; x86 -client: 12.]-client: 4 (1.3) 8 (1.3.1+), x86: 12] -XX:NewSize=2m Default size of new generation (in bytes) [5.0 and newer: 64 bit VMs are scaled 30% larger; x86: 1m; x86, 5.0 and older: 640k] -XX:ReservedCodeCacheSize=32m Reserved code cache size (in bytes) - maximum code cache size. [Solaris 64-bit, amd64, and -server x86: 2048m; in 1.5.0_06 and earlier, Solaris 64-bit and amd64: 1024m.] -XX:SurvivorRatio=8 Ratio of eden/survivor space size [Solaris amd64: 6; Sparc in 1.3.1: 25; other Solaris platforms in 5.0 and earlier: 32] -XX:TargetSurvivorRatio=50 Desired percentage of survivor space used after scavenge. -XX:ThreadStackSize=512 Thread Stack Size (in Kbytes). (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.] -XX:-UseBiasedLocking 取消偏向锁，大量多线程并发，锁会从偏向所升级，取消反而有性能提升 -XX:+UseFastAccessorMethods Use optimized versions of GetField. -XX:-UseISM Use Intimate Shared Memory. [Not accepted for non-Solaris platforms.] For details, see Intimate Shared Memory. -XX:+UseLargePages Use large page memory. (Introduced in 5.0 update 5.) For details, see Java Support for Large Memory Pages. -XX:+UseMPSS Use Multiple Page Size Support w/4mb pages for the heap. Do not use with ISM as this replaces the need for ISM. (Introduced in 1.4.0 update 1, Relevant to Solaris 9 and newer.) [1.4.1 and earlier: false] -XX:+UseStringCache Enables caching of commonly allocated strings. -XX:AllocatePrefetchLines=1 Number of cache lines to load after the last object allocation using prefetch instructions generated in JIT compiled code. Default values are 1 if the last allocated object was an instance and 3 if it was an array. -XX:AllocatePrefetchStyle=1 Generated code style for prefetch instructions. 0 - no prefetch instructions are generated, 1 - execute prefetch instructions after each allocation, 2 - use TLAB allocation watermark pointer to gate when prefetch instructions are executed. -XX:+UseCompressedStrings Use a byte[] for Strings which can be represented as pure ASCII. (Introduced in Java 6 Update 21 Performance Release) -XX:+OptimizeStringConcat Optimize String concatenation operations where possible. (Introduced in Java 6 Update 20) Debugging Options Option and Default Value Description -XX:-CITime Prints time spent in JIT Compiler. (Introduced in 1.4.0.) -XX:ErrorFile=./hs_err_pid.log If an error occurs, save the error data to this file. (Introduced in 6.) -XX:-ExtendedDTraceProbes Enable performance-impacting dtrace probes. (Introduced in 6. Relevant to Solaris only.) -XX:HeapDumpPath=./java_pid.hprof 设置内存快照目录 -XX:+HeapDumpOnOutOfMemoryError 在OOM时，输出一个dump.core文件，记录当时堆内存快照 -XX:OnError=”;“ Run user-defined commands on fatal error. (Introduced in 1.4.2 update 9.) -XX:OnOutOfMemoryError=”; “ Run user-defined commands when an OutOfMemoryError is first thrown. (Introduced in 1.4.2 update 12, 6) -XX:-PrintClassHistogram Print a histogram of class instances on Ctrl-Break. Manageable. (Introduced in 1.4.2.) The jmap -histocommand provides equivalent functionality. -XX:-PrintConcurrentLocks Print java.util.concurrent locks in Ctrl-Break thread dump. Manageable. (Introduced in 6.) The jstack -lcommand provides equivalent functionality. -XX:-PrintCommandLineFlags Print flags that appeared on the command line. (Introduced in 5.0.) -XX:-PrintCompilation Print message when a method is compiled. -XX:-PrintGC Print messages at garbage collection. Manageable. -XX:-PrintGCDetails Print more details at garbage collection. Manageable. (Introduced in 1.4.0.) -XX:-PrintGCTimeStamps Print timestamps at garbage collection. Manageable(Introduced in 1.4.0.) -XX:-PrintTenuringDistribution 查看survivor区对象大部分多少次进老年代 -XX:-PrintAdaptiveSizePolicy Enables printing of information about adaptive generation sizing. -XX:-TraceClassLoading Trace loading of classes. -XX:-TraceClassLoadingPreorder Trace all classes loaded in order referenced (not loaded). (Introduced in 1.4.2.) -XX:-TraceClassResolution Trace constant pool resolutions. (Introduced in 1.4.2.) -XX:-TraceClassUnloading Trace unloading of classes. -XX:-TraceLoaderConstraints Trace recording of loader constraints. (Introduced in 6.) -XX:+PerfDataSaveToFile Saves jvmstat binary data on exit. -XX:ParallelGCThreads=n Sets the number of garbage collection threads in the young and old parallel garbage collectors. The default value varies with the platform on which the JVM is running. -XX:+UseCompressedOops Enables the use of compressed pointers (object references represented as 32 bit offsets instead of 64-bit pointers) for optimized 64-bit performance with Java heap sizes less than 32gb. -XX:+AlwaysPreTouch 为了避免多次内存分配的开销，让HotSpot VM在commit内存时跑个循环来强制保证申请的内存真的commit了 -XX:AllocatePrefetchDistance=n Sets the prefetch distance for object allocation. Memory about to be written with the value of new objects is prefetched into cache at this distance (in bytes) beyond the address of the last allocated object. Each Java thread has its own allocation point. The default value varies with the platform on which the JVM is running. -XX:InlineSmallCode=n Inline a previously compiled method only if its generated native code size is less than this. The default value varies with the platform on which the JVM is running. -XX:MaxInlineSize=35 Maximum bytecode size of a method to be inlined. -XX:FreqInlineSize=n Maximum bytecode size of a frequently executed method to be inlined. The default value varies with the platform on which the JVM is running. -XX:LoopUnrollLimit=n Unroll loop bodies with server compiler intermediate representation node count less than this value. The limit used by the server compiler is a function of this value, not the actual value. The default value varies with the platform on which the JVM is running. -XX:InitialTenuringThreshold=7 Sets the initial tenuring threshold for use in adaptive GC sizing in the parallel young collector. The tenuring threshold is the number of times an object survives a young collection before being promoted to the old, or tenured, generation. -XX:MaxTenuringThreshold=n Sets the maximum tenuring threshold for use in adaptive GC sizing. The current largest value is 15. The default value is 15 for the parallel collector and is 4 for CMS. -Xloggc: Log GC verbose output to specified file. The verbose output is controlled by the normal verbose GC flags. -XX:-UseGCLogFileRotation Enabled GC log rotation, requires -Xloggc. -XX:NumberOfGClogFiles=1 Set the number of files to use when rotating logs, must be &gt;= 1. The rotated log files will use the following naming scheme, .0, .1, …, .n-1. -XX:GCLogFileSize=8K The size of the log file at which point the log will be rotated, must be &gt;= 8K.]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC日志]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2FGC%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[垃圾收集器长时间停顿，表现在 Web 页面上可能是页面响应码 500 之类的服务器错误问题，如果是个支付过程可能会导致支付失败，将造成公司的直接经济损失。 MetaSpace内存溢出JDK8 使用 MetaSpace 来保存类加载之后的类信息，字符串常量池也被移动到 Java 堆 JDK 8 中将类信息移到到了本地堆内存(Native Heap)中，将原有的永久代移动到了本地堆中成为 MetaSpace ,如果不指定该区域的大小，JVM 将会动态的调整。 可以使用 -XX:MaxMetaspaceSize=10M 来限制最大元数据。这样当不停的创建类时将会占满该区域并出现 OOM 动态代理对象太多也会 oom动态代理生成的对象在Jvm中指向的不是同一个地址，它只是与源对象有相同的hashcode值而已 CMS (concurrent mode failure) 老年代碎片化严重，无法容纳新生代提升上来的大对象 新生代来不及回收，老年代被用完 发送这种情况，应用线程将会全部停止（相当于网站这段时间无法响应用户请求），进行压缩式垃圾收集（回退到 Serial Old 算法） 解决办法： 新生代提升过快问题：（1）如果频率太快的话，说明空间不足，首先可以尝试调大新生代空间和晋升阈值。（2）如果内存有限，可以设置 CMS 垃圾收集在老年代占比达到多少时启动来减少问题发生频率（越早启动问题发生频率越低，但是会降低吞吐量，具体得多调整几次找到平衡点），参数如下：如果没有第二个参数，会随着 JVM 动态调节 CMS 启动时间 -XX:CMSInitiatingOccupancyFraction=68 （默认是 68） -XX:+UseCMSInitiatingOccupancyOnly 老年代碎片严重问题：（1）如果频率太快或者 Full GC 后空间释放不多的话，说明空间不足，首先可以尝试调大老年代空间（2）如果内存不足，可以设置进行 n 次 CMS 后进行一次压缩式 Full GC，参数如下： -XX:+UseCMSCompactAtFullCollection：允许在 Full GC 时，启用压缩式 GC -XX:CMSFullGCBeforeCompaction=n 在进行 n 次，CMS 后，进行一次压缩的 Full GC，用以减少 CMS 产生的碎片 CMS (promotion failed)在 Minor GC 过程中，Survivor Unused 可能不足以容纳 Eden 和另一个 Survivor 中的存活对象， 那么多余的将被移到老年代， 称为过早提升（Premature Promotion）。 这会导致老年代中短期存活对象的增长， 可能会引发严重的性能问题。 再进一步， 如果老年代满了， Minor GC 后会进行 Full GC， 这将导致遍历整个堆， 称为提升失败（Promotion Failure）。 提升失败日志： 提升失败原因：Minor GC 时发现 Survivor 空间放不下，而老年代的空闲也不够 新生代提升太快 老年代碎片太多，放不下大对象提升（表现为老年代还有很多空间但是，出现了 promotion failed） 解决方法：是调整年轻代和年老代的比例，还有CMSGC的时机 ​ 两条和上面 concurrent mode failure 一样 ​ 另一条，是因为 Survivor Unused 不足，那么可以尝试调大 Survivor 来尝试下 三. 在 GC 的时候其他系统活动影响 有些时候系统活动诸如内存换入换出（vmstat）、网络活动（netstat）、I/O （iostat）在 GC 过程中发生会使 GC 时间变长。 前提是你的服务器上是有 SWAP 区域（用 top、 vmstat 等命令可以看出）用于内存的换入换出，那么操作系统可能会将 JVM 中不活跃的内存页换到 SWAP 区域用以释放内存给线程使用（这也透露出内存开始不够用了）。内存换入换出是一个开销巨大的磁盘操作，比内存访问慢好几个数量级。 看一段 GC 日志：耗时 29.47 秒 再看看此时的 vmstat 命令中 si、so 列的数值，如果数值大说明换入换出严重，这是内存不足的表现。 解决方法：减少线程，这样可以降低内存换入换出；增加内存；如果是 JVM 内存设置过大导致线程所用内存不足，则适当调低 -Xmx 和 -Xms。 五. 总结 ​ 长时间停顿问题的排查及解决首先需要一定的信息和方法论： 详细的 GC 日志 借助 Linux 平台下的 iostat、vmstat、netstat、mpstat 等命令监控系统情况 查看 GC 日志中是否出现了上述的典型内存异常问题（promotion failed, concurrent mode failure），整体来说把上述两个典型内存异常情况控制在可接受的发生频率即可，对 CMS 碎片问题来说杜绝以上问题似乎不太可能，只能靠 G1 来解决了 是不是 JVM 本身的 bug 导致的 如果程序没问题，参数调了几次还是不能解决，可能说明流量太大，需要加机器把压力分散到更多 JVM 上 gc常见错误java.lang.OutOfMemoryError: Java heap space 原因：Heap内存溢出，意味着Young和Old generation的内存不够。 解决：调整java启动参数-Xms -Xmx 来增加Heap内存。 java.lang.OutOfMemoryError: unable to create new native thread 原因：Stack空间不足以创建额外的线程，要么是创建的线程过多，要么是Stack空间确实小了。 解决：由于JVM没有提供参数设置总的stack空间大小，但可以设置单个线程栈的大小；而系统的用户空间一共是3G，除了Text/Data/BSS /MemoryMapping几个段之外，Heap和Stack空间的总量有限，是此消彼长的。因此遇到这个错误，可以通过两个途径解决：1.通过 -Xss启动参数减少单个线程栈大小，这样便能开更多线程（当然不能太小，太小会出现StackOverflowError）；2.通过-Xms -Xmx 两参数减少Heap大小，将内存让给Stack（前提是保证Heap空间够用）。 java.lang.OutOfMemoryError: Requested array size exceeds VM limit 原因：这个错误比较少见（试着new一个长度1亿的数组看看），同样是由于Heap空间不足。如果需要new一个如此之大的数组，程序逻辑多半是不合理的。 解决：修改程序逻辑吧。或者也可以通过-Xmx来增大堆内存。 在GC花费了大量时间，却仅回收了少量内存时，也会报出OutOfMemoryError ，我只遇到过一两次。当使用-XX:+UseParallelGC或-XX:+UseConcMarkSweepGC收集器时，在上述情况下会报错，在 HotSpot GC Turning文档 上有说明： The parallel(concurrent) collector will throw an OutOfMemoryError if too much time is being spent in garbage collection: if more than 98% of the total time is spent in garbage collection and less than 2% of the heap is recovered, an OutOfMemoryError will be thrown. 对这个问题，一是需要进行GC turning，二是需要优化程序逻辑。 java.lang.StackOverflowError 原因：这也内存溢出错误的一种，即线程栈的溢出，要么是方法调用层次过多（比如存在无限递归调用），要么是线程栈太小。 解决：优化程序设计，减少方法调用层次；调整-Xss参数增加线程栈大小。 IOException: Too many open files 原因： 这个是由于TCP connections 的buffer 大小不够用了。 java.lang.OutOfMemoryError:Direct buffer memory 解决：调整-XX:MaxDirectMemorySize=]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾回收]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2F%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[判断是否可回收引用计数算法 给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收，JVM不使用 可达性算法 通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。 在 Java 中 GC Roots 一般包含以下内容： 虚拟机栈中局部变量表中引用的对象 本级方法栈(Native方法)引用的对象 方法区中类静态变量引用的对象 方法区中的常量引用的对象 方法区回收 主要是对常量池的回收和对类的卸载。在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例 加载该类的 ClassLoader 已经被回收 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法 垃圾收集算法标记 - 清除标记存活的对象，将未被标记的对象清除 缺点： 标记和清除过程效率都不高 会产生大量不连续的内存碎片，导致无法给大对象分配内存 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理 JVM新生代中是这么做的：新生代分为一块较大的 Eden区和两块较小的Survivor区，每次使用Eden区和其中一块Survivor区。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor 标记 - 整理将存活的对象集中起来，使其内存连续，将边界以外的内存清除 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 垃圾收集器 SerialClient 模式下的默认新生代收集器，单线程的收集器，优点是简单高效，对于单个 CPU 环境来说，由于没有线程交互的开销，因此拥有最高的单线程收集效率。缺点是回收时会将正在执行的线程暂停。适用于单CPU、新生代空间较小及对暂停时间要求不是非常高的应用上 Parallel Scavenge吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间）-XX:MaxGCPauseMillis=n 控制最大垃圾收集停顿时间-XX:GCTimeRatio=n 设置吞吐量大小的垃圾收集时间占总时间的比率，设置为19 最大gc时间就占总的1/20-XX:UseAdaptiveSizePolicy GC Ergonomics 动态调整java堆中各个区域的大小和年龄 多线程收集器。其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。 缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。 可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 ParNew-XX:ParallelGCThreads Server 模式下的虚拟机首选新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合工作 默认开启的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数 在整个扫描和复制过程采用多线程的方式来进行，适用于多CPU、对暂停时间要求较短的应用上，用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数 Serial OldCMS备用预案 Concurrent Mode Failusre时使用标记-整理算法 Serial收集器的老年代版本，它同样使用一个单线程执行收集，基于标记整理法，作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用 Parallel Old标记-整理算法 Parallel Scavenge收集器的老年代版本，使用多线程和标记整理法，在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器，可以用在注重吞吐量和CPU资源敏感的场合,UsePallelOldGC打开 CMS标记-清除算法减少回收停顿时间碎片 -XX:CMSInitiatingOccupancyFraction 被使用多少后触发垃圾收集，提高cms触发百分比Concurrent Mode Failure 启用Serial Old 123-XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction 执行多少次不压缩FullGC后 来一次带压缩的 0 表示每次都压-XX:+UseConcMarkSweep Concurrent Mark Sweep，基于标记清除法。目标是解决Serial GC 的停顿问题，以达到最短回收时间，有高并发、高响应的特点 初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿 并发标记(CMS concurrenr mark) 进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿 重新标记(CMS remark) 为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿 并发清除(CMS concurrent sweep)不需要停顿 缺点： 产生大量碎片，大内存找不到连续的空间 会full gc 通过-XX:CMSFullGCBeforeCompaction参数设置执行多少次不压缩的Full GC之后，跟着来一次碎片整理，默认为0，即每次Full GC都对老生代进行碎片整理压缩。Full GC 不同于 老生代75%时触发的CMS GC，只在老生代达到100%，堆外内存满，老生代碎片过大无法分配空间给新晋升的大对象这些特殊情况里发生，所以设为每次都进行碎片整理是合适的 无法清除浮动垃圾 在默认设置下，CMS收集器在老年代使用了68%的空间时就会被激活，也可以通过参数-XX:CMSInitiatingOccupancyFraction的值来提供触发百分比。可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 占用cpu资源 导致程序变慢，吞吐量下降 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高 G1-XX:+UseG1GC 使用G1垃圾收集器 面向Server的垃圾收集器，相比CMS有不少改进，在多 CPU 和大内存的场景下有很好的性能。G1 可以直接对新生代和老年代一起回收 。优点： 整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片 能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒 通过引入 Region （区域）的概念，将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。通过记录每个 Region 垃圾回收时间以及回收所获得的空间，并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 具备如下特点： 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 收集器 串行/并行/并发 新生代/老年代 算法 优先目标 适用场景 Serial 串行 新生代 复制算法 响应速度 单CPU的Client模式 Serial Old 串行 老年代 标记-整理 响应速度 单CPU的Client模式、CMS的后备预案 ParNew 并行 新生代 复制算法 响应速度 多CPU时在Server模式下与CMS配合 Parallel Scavenge 并行 新生代 复制算法 吞吐量 在后台运算而不需要太多交互的任务 Parallel Old 并行 老年代 标记-整理 吞吐量 在后台运算而不需要太多交互的任务 CMS 并发 老年代 标记-清除 响应速度 集中在互联网站或B/S系统服务端上的Java应用 G1 并发 新生代和老年代 标记-整理+复制算法 响应速度 面向服务端应用，将来替换CMS 串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序 并行指的是垃圾收集器和用户程序同时执行 内存分配策略 对象优先在eden区分配内存，eden区空间不够时出发minor gc 大对象直接进入老年代 -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 区和 Survivor 区之间的大量内存复制 长期存活的进入老年代在新生代多次gc存活下来的进入老年代 -XX:MaxTenuringThreshold 用来定义经过多少次minor gc还存活后进入老年代 动态对象年龄判定当 Survivor 中相同年龄所有对象大小的总和&gt; Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需经过 MaxTenuringThreshold 次gc 空间分配担保在 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。 如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC TLAB thread local allcationnnotion buffer 在eden区 每隔线程都有自己的 TLAB thread local allaction buffer 触发条件minor gc当 eden 空间满时，就将触发一次 minor gc，清理eden区 major gc是清理老年代 full gc清理整个堆空间—包括年轻代和老年代 空间分配担保失败触发full gc minor gc之前检查 老年代最大可用连续空间是否&gt;新生代所有对象总空间 调用System.gc时，系统建议执行Full GC，但是不必然执行 老年代空间不足 大对象直接进入老年代，长期存活的对象进入老年代，老年代没有足够大小的连续内存空间，触发full gc 方法区空间不足 通过Minor GC后进入老年代的平均大小大于老年代的可用内存 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 如何查看当前的垃圾回收器​ -XX:+PrintFlagsFinal​ -XX:+PrintCommandLineFlags​ server client​ MBean GC日志​ 1.输出日志​ -XX:+PrintGCTimeStamps​ -XX:+PrintGCDetails​ -Xloggc:/home/administrator/james/gc.log​ -XX:+PrintHeapAtGC​ 2.日志文件控制​ -XX:-UseGCLogFileRotation​ -XX:GCLogFileSize=8K​ 3.怎么看 JDK自带的 监控工具https://docs.oracle.com/javase/8/docs/technotes/tools/windows/toc.html​ jmap -heap pid 堆使用情况​ jstat -gcutil pid 1000​ jstack 线程dump​ jvisualvm​ jconsole MAT​ http://help.eclipse.org/oxygen/index.jsp?topic=/org.eclipse.mat.ui.help/welcome.html​ -XX:+HeapDumpOnOutOfMemoryError​ -XX:HeapDumpPath=/home/administrator/james/error.hprof 怀疑：​ 1.看GC日志 126719K-&gt;126719K(126720K)​ 2.dump​ 3.MAT​ 1.占用Retained Heap​ 2.看有没有GC Root指向 什么条件触发STW的Full GC呢？Perm空间不足；CMS GC时出现promotion failed和concurrent mode failure（concurrent mode failure发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再被使用的对象，这时停止所有的线程，同时终止CMS，直接进行Serial Old GC）；（promontion faild产生的原因是EDEN空间不足的情况下将EDEN与From survivor中的存活对象存入To survivor区时,To survivor区的空间不足，再次晋升到old gen区，而old gen区内存也不够的情况下产生了promontion faild从而导致full gc ） 统计得到的Young GC晋升到老年代的平均大小大于老年代的剩余空间； 主动触发Full GC（执行jmap -histo:live [pid]）来避免碎片问题。​​java -Xms8m -Xmx64m -verbose:gc -Xloggc:/home/administrator/james/gc.log -XX:+PrintHeapAtGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCTimeStamps -XX:+PrintCommandLineFlags -XX:+PrintFlagsFinal -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9004 -Djava.rmi.server.hostname=177.1.1.122 -jar jvm-demo1-0.0.1-SNAPSHOT.jar &gt; catalina.out 2&gt;&amp;1 &amp; java -Xms128m -Xmx128m -verbose:gc -Xloggc:/home/administrator/james/gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/administrator/james/error.hprof -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCTimeStamps -XX:+PrintCommandLineFlags -XX:+PrintFlagsFinal -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9004 -Djava.rmi.server.hostname=177.1.1.122 -jar jvm-demo1-0.0.1-SNAPSHOT.jar &gt; catalina.out 2&gt;&amp;1 &amp; java -Xms128m -Xmx128m -verbose:gc -Xloggc:/home/administrator/james/gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintHeapAtGC -XX:HeapDumpPath=/home/administrator/james/error.hprof -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCTimeStamps -XX:+PrintCommandLineFlags -XX:+PrintFlagsFinal -XX:+PrintGCDetails -XX:+UseCMSCompactAtFullCollection -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9004 -Djava.rmi.server.hostname=177.1.1.122 -jar jvm-demo1-0.0.1-SNAPSHOT.jar &gt; catalina.out 2&gt;&amp;1 &amp; -XX:+CMSScavengeBeforeRemark]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM组成]]></title>
    <url>%2F2018%2F11%2F03%2FJVM%2FJVM%E7%BB%84%E6%88%90%2F</url>
    <content type="text"><![CDATA[方法区和堆内存是线程共享的。程序计数器、虚拟机栈、本地方法栈是线程私有的 方法区存放已经被JVM加载的类的信息，如常量，静态变量、即时编译器编译后的代码等。 从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中，1.8 metaspace 放类加载信息 堆内存 所有对象的创建都在这里进行分配，采取分代管理，分为新生代和老年代，执行不同的垃圾回收策略，所有实例域，静态域和数组元素都是放在堆内存中。常量池在堆中 程序计数器指向当前线程执行的字节码行号，多线程切换时可以知道上一次运行的状态和位置 虚拟机栈 由一个个栈帧组成，每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用、方法的调用返回等信息，每创建一个栈帧压栈，当一个方法执行完毕之后则出栈 该区域可能抛出以下异常： 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常 本地方法栈调用Native Method 直接内存在 JDK 1.4 中新加入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存（Native 堆），然后通过一个存储在 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stream流]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FStream%E6%B5%81%2F</url>
    <content type="text"><![CDATA[StreamJava8的新增的Stream API（java.util.stream）将生成环境的函数式编程引入了Java库中。这是目前为止最大的一次对Java库的完善，以便开发者能够写出更加有效、更加简洁和紧凑的代码。Steam API极大得简化了集合操作，Stream流配合Lambda表达式使用起来真是美滋滋，steam的另一个价值是创造性地支持并行处理。 优点：性能高，灵活，表达清楚 方法api分为两大类，中间操作相当于流水线，能对流水线上的东西进行各种处理，不会消耗流；终端操作消耗流，不能再对流进行操作 中间操作(流水线) filter 过滤 map 抽取流 limit 限制个数 skip 跳过个数 sorted 排序 distinct 去重 flagmap 合并到一起 终端操作(消耗流) collect 收集 foreach 遍历 count 计数 anyMatch 至少匹配1个 allMatch 匹配所有 noneMatch 没有元素匹配 findAny 返回流中任意元素 reduce 举例12345678910111213141516171819202122232425import java.util.ArrayList;import java.util.Comparator;import java.util.List;import java.util.Map;import java.util.stream.Collectors;public class StreamTest &#123; public static void main(String[] args) &#123; List&lt;Apple&gt; appleList=new ArrayList&lt;&gt;(); appleList.parallelStream().filter((e)-&gt;e.getWeight()&gt;50) // 筛选重量&gt;50的苹果 .sorted(Comparator.comparing(Apple::getColor)) // 根据苹果的颜色进行排序 .map(Apple::getWeight) // 抽取苹果中的重量 .limit(3) // 限定选3个 .distinct() // 去掉相同的元素 .collect(Collectors.toList()); // 转化成list appleList.forEach(System.out::println); // 打印每个苹果 appleList.stream().count(); // 计算苹果的总个数 // 对list根据苹果的颜色进行分组 Map&lt;String,List&lt;Apple&gt;&gt; map=appleList.parallelStream().collect(Collectors.groupingBy(Apple::getColor)); &#125;&#125; flagmap合并流 123456789101112public class StreamTest &#123; public static void main(String[] args) &#123; List&lt;String&gt; names = new ArrayList&lt;&gt;(); names.add("hello"); names.add("world"); List&lt;String&gt; a=names.stream().map((String e)-&gt;e.split("")) .flatMap(Arrays::stream) .collect(Collectors.toList());// 将两个单词，拆成单个字母并存为list System.out.println(a.get(9)); &#125;&#125; reduce 123456789101112public class StreamTest &#123; public static void main(String[] args) &#123; List&lt;String&gt; names = new ArrayList&lt;&gt;(); names.add("hello"); names.add("world"); String newstr=names.stream().map((String e)-&gt;e.split("")) .flatMap(Arrays::stream) .reduce("",String::concat);// 拆成字母后，拼接成一个新的字符串，相当于.reduce("",(String a ,String b)-&gt;a+b); System.out.println(newstr); &#125;&#125; collect 123List&lt;Apple&gt; appleList=new ArrayList&lt;&gt;();appleList.stream().collect(Collectors.averagingInt(Apple::getWeight));// 计算重量的平均值appleList.stream().map(Apple::getColor).collect(Collectors.joining());// 连接字符串 创建流的方式值创建流 1Stream&lt;String&gt; strstream=Stream.of(&quot;dasd&quot;,&quot;dsa&quot;,&quot;das&quot;); 数据创建流 12String[] nums=&#123;&quot;qwe&quot;,&quot;ee&quot;,&quot;ds&quot;&#125;;Stream&lt;String&gt; aaa=Arrays.stream(nums); 文件创建流 123456try &#123; Stream&lt;String&gt; lines=Files.lines(Paths.get(&quot;C:\\Users\\maruami\\Desktop\\readbook\\book.md&quot;), Charset.defaultCharset()); lines.forEach(System.out::println);&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 函数生成流 1Stream.generate(Math::random).limit(10).forEach(System.out::println);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda表达式]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Lambda表达式Lambda 表达式，它是推动 Java 8 发布的最重要新特性。Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中），可以使代码变的更加简洁紧凑。 基本语法：1(参数列表) -&gt; &#123;代码块&#125; 需要注意： 参数类型可省略，编译器可以自己推断 如果只有一个参数，圆括号可以省略 代码块如果只是一行代码，大括号也可以省略 如果代码块是一行，且是有结果的表达式，return可以省略 注意：事实上，把Lambda表达式可以看做是匿名内部类的一种简写方式。当然，前提是这个匿名内部类对应的必须是接口，而且接口中必须只有一个函数！Lambda表达式就是直接编写函数的：参数列表、代码体、返回值等信息。 用法示例排序12345// 准备一个集合List&lt;Integer&gt; list = Arrays.asList(10, 5, 25, -15, 20);list.sort((i1,i2) -&gt; &#123; return i1 - i2;&#125;);System.out.println(list);//output [-15, 5, 10, 20, 25] 还可以简写为： 1list.sort((i1,i2) -&gt; i1 - i2); 遍历1list.forEach(i -&gt; System.out.println(i)); 赋值Lambda表达式的实质其实还是匿名内部类，所以我们其实可以把Lambda表达式赋值给某个变量。 1Runnable task = () -&gt; &#123;System.out.println("hello lambda!");&#125;; 隐式finalLambda表达式的实质其实还是匿名内部类，而匿名内部类在访问外部局部变量时，要求变量必须声明为final。不过我们在使用Lambda表达式时无需声明final，因为Lambda底层会隐式的把变量设置为final，在后续的操作中，一定不能修改该变量。 1234// 定义一个局部变量int num = -1;// 在Lambda表达式中使用局部变量num，num会被隐式声明为final，不能进行任何修改操作Runnable r = () -&gt; &#123;System.out.println(num);&#125;; 函数式接口 Lambda表达式是接口的匿名内部类的简写形式 接口必须满足：内部只有一个函数 其实这样的接口，我们称为函数式接口，我们学过的Runnable、Comparator都是函数式接口的典型代表。但是在实践中，函数接口是非常脆弱的，只要有人在接口里添加多一个方法，那么这个接口就不是函数接口了，就会导致编译失败。Java 8提供了一个特殊的注解@FunctionalInterface来克服上面提到的脆弱性并且显示地表明函数接口。而且jdk8版本中，对很多已经存在的接口都添加了@FunctionalInterface注解，例如Runnable接口，另外，Jdk8默认提供了一些函数式接口供我们使用： Function类型接口12345@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; // 接收一个参数T，返回一个结果R R apply(T t);&#125; Function代表的是有参数，有返回值的函数。还有很多类似的Function接口： 接口名 描述 BiFunction&lt;T,U,R&gt; 接收两个T和U类型的参数，并且返回R类型结果的函数 DoubleFunction&lt;R&gt; 接收double类型参数，并且返回R类型结果的函数 IntFunction&lt;R&gt; 接收int类型参数，并且返回R类型结果的函数 LongFunction&lt;R&gt; 接收long类型参数，并且返回R类型结果的函数 ToDoubleFunction&lt;T&gt; 接收T类型参数，并且返回double类型结果 ToIntFunction&lt;T&gt; 接收T类型参数，并且返回int类型结果 ToLongFunction&lt;T&gt; 接收T类型参数，并且返回long类型结果 DoubleToIntFunction 接收double类型参数，返回int类型结果 DoubleToLongFunction 接收double类型参数，返回long类型结果 这些都是一类函数接口，在Function基础上衍生出的，要么明确了参数不确定返回结果，要么明确结果不知道参数类型，要么两者都知道。 Consumer12345@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123; // 接收T类型参数，不返回结果 void accept(T t);&#125; 具备类似的特征：那就是不返回任何结果。 Predicate12345@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; // 接收T类型参数，返回boolean类型结果 boolean test(T t);&#125; Predicate系列参数不固定，但是返回的一定是boolean类型。 Supplier12345@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; // 无需参数，返回一个T类型结果 T get();&#125; 不接受任何参数，返回T类型结果。 方法引用方法引用使得开发者可以将已经存在的方法作为变量来传递使用。方法引用可以和Lambda表达式配合使用。 语法 语法 描述 类名::静态方法名 类的静态方法的引用 类名::非静态方法名 类的非静态方法的引用 实例对象::非静态方法名 类的指定实例对象的非静态方法引用 类名::new 类的构造方法引用 示例首先我们编写一个集合工具类，提供一个方法： 123456789101112131415public class CollectionUtil&#123; /** * 利用function将list集合中的每一个元素转换后形成新的集合返回 * @param list 要转换的源集合 * @param function 转换元素的方式 * @param &lt;T&gt; 源集合的元素类型 * @param &lt;R&gt; 转换后的元素类型 * @return */ public static &lt;T,R&gt; List&lt;R&gt; convert(List&lt;T&gt; list, Function&lt;T,R&gt; function)&#123; List&lt;R&gt; result = new ArrayList&lt;&gt;(); list.forEach(t -&gt; result.add(function.apply(t))); return result; &#125;&#125; 可以看到这个方法接收两个参数： List&lt;T&gt; list：需要进行转换的集合 Function&lt;T,R&gt;：函数接口，接收T类型，返回R类型。用这个函数接口对list中的元素T进行转换，变为R类型 类的静态方法引用1List&lt;Integer&gt; list = Arrays.asList(1000, 2000, 3000); 我们需要把这个集合中的元素转为十六进制保存，需要调用Integer.toHexString()方法： 123public static String toHexString(int i) &#123; return toUnsignedString0(i, 4);&#125; 这个方法接收一个 i 类型，返回一个String类型，可以用来构造一个Function的函数接口： 我们先按照Lambda原始写法，传入的Lambda表达式会被编译为Function接口，接口中通过Integer.toHexString(i)对原来集合的元素进行转换： 123// 通过Lambda表达式实现List&lt;String&gt; hexList = CollectionUtil.convert(list, i -&gt; Integer.toHexString(i));System.out.println(hexList);// [3e8, 7d0, bb8] 上面的Lambda表达式代码块中，只有对Integer.toHexString()方法的引用，没有其它代码，因此我们可以直接把方法作为参数传递，由编译器帮我们处理，这就是静态方法引用： 123// 类的静态方法引用List&lt;String&gt; hexList = CollectionUtil.convert(list, Integer::toHexString);System.out.println(hexList);// [3e8, 7d0, bb8] 类的非静态方法引用接下来，我们把刚刚生成的String集合hexList中的元素都变成大写，需要借助于String类的toUpperCase()方法： 123public String toUpperCase() &#123; return toUpperCase(Locale.getDefault());&#125; 这次是非静态方法，不能用类名调用，需要用实例对象，因此与刚刚的实现有一些差别，我们接收集合中的每一个字符串s。但与上面不同然后s不是toUpperCase()的参数，而是调用者： 123// 通过Lambda表达式，接收String数据，调用toUpperCase()List&lt;String&gt; upperList = CollectionUtil.convert(hexList, s -&gt; s.toUpperCase());System.out.println(upperList);// [3E8, 7D0, BB8] 因为代码体只有对toUpperCase()的调用，所以可以把方法作为参数引用传递，依然可以简写： 123// 类的成员方法List&lt;String&gt; upperList = CollectionUtil.convert(hexList, String::toUpperCase);System.out.println(upperList);// [3E8, 7D0, BB8] 指定实例的非静态方法引用下面一个需求是这样的，我们先定义一个数字Integer num = 2000，然后用这个数字和集合中的每个数字进行比较，比较的结果放入一个新的集合。比较对象，我们可以用Integer的compareTo方法: 123public int compareTo(Integer anotherInteger) &#123; return compare(this.value, anotherInteger.value);&#125; 先用Lambda实现， 123456List&lt;Integer&gt; list = Arrays.asList(1000, 2000, 3000);// 某个对象的成员方法Integer num = 2000;List&lt;Integer&gt; compareList = CollectionUtil.convert(list, i -&gt; num.compareTo(i));System.out.println(compareList);// [1, 0, -1] 与前面类似，这里Lambda的代码块中，依然只有对num.compareTo(i)的调用，所以可以简写。但是，需要注意的是，这次方法的调用者不是集合的元素，而是一个外部的局部变量num，因此不能使用 Integer::compareTo，因为这样是无法确定方法的调用者。要指定调用者，需要用 对象::方法名的方式： 1234// 某个对象的成员方法Integer num = 2000;List&lt;Integer&gt; compareList = CollectionUtil.convert(list, num::compareTo);System.out.println(compareList);// [1, 0, -1] 构造函数引用最后一个场景：把集合中的数字作为毫秒值，构建出Date对象并放入集合，这里我们就需要用到Date的构造函数： 1234567/** * @param date the milliseconds since January 1, 1970, 00:00:00 GMT. * @see java.lang.System#currentTimeMillis() */public Date(long date) &#123; fastTime = date;&#125; 我们可以接收集合中的每个元素，然后把元素作为Date的构造函数参数： 1234// 将数值类型集合，转为Date类型List&lt;Date&gt; dateList = CollectionUtil.convert(list, i -&gt; new Date(i));// 这里遍历元素后需要打印，因此直接把println作为方法引用传递了dateList.forEach(System.out::println); 上面的Lambda表达式实现方式，代码体只有new Date()一行代码，因此也可以采用方法引用进行简写。但问题是，构造函数没有名称，我们只能用new关键字来代替： 123// 构造方法List&lt;Date&gt; dateList = CollectionUtil.convert(list, Date::new);dateList.forEach(System.out::println); 注意两点： 上面代码中的System.out::println 其实是 指定对象System.out的非静态方法println的引用 如果构造函数有多个，可能无法区分导致传递失败]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Collections]]></title>
    <url>%2F2018%2F11%2F03%2FJava%2FCollections%2F</url>
    <content type="text"><![CDATA[method description max(coll)/max(coll, comp) Collections.max(map.values(),(e1,e2)-&gt;{return e1.length()-e2.length();}); min(coll)/min(coll, comp) indexOfSubList(source, target) 返回target在source中第一次出现的位置 lastIndexOfSubList(source, target); 返回target在source中最后一次出现的位置 reverse(source) 逆置元素 rotate(list, distance) 所有元素向后移动distance个位置，末尾元素循环到前面 Collections.swap(list, 1, 2); 交换list中元素的位置 disjoint(c1,c2) 没有相同元素，返回true frequency(collection, object) 返回collection中等于object的个数]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Collections</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala入门]]></title>
    <url>%2F2018%2F11%2F02%2FScala%2FScala%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Scala是一个面向对象和函数式编程的语言，运行于JVM之上，兼容Java程序 结尾不写；和Python有点像 类型声明，推测和Go有点像 scalac xxx.scala 编译Scala文件，生成Class字节码文件 scala xxx 运行字节码文件 卧槽和Java好像 scala没有原生类型 var 变量 val常量 访问修饰符与Java不同 protected 只能被子类访问 private 只能内部可见 外部类调用不了内部类的私有方法 http://www.runoob.com/scala/scala-functions.html]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语句优化]]></title>
    <url>%2F2018%2F10%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FSQL%E8%AF%AD%E5%8F%A5%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[只返回必要的列，减少查询字段数，不使用select * 只返回必要的行 limit限制返回的数据， 确定只要一行数据时使用limit 1 缓存重复查询的数据 使用索引减少扫描次数 切分大查询 如果一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询，所以要切分 分解大连接查询 让缓存更高效 对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符 冷热数据分离 历史数据归档 不使用uuid md5 hash 字符串作为主键 使用分区表 逻辑上是一张表 物理上存在不同的表上（list,hash,range） 避免使用子查询 会产生大量的临时表 子查询的没有索引 合理使用join，表关联尽量用主键 where 从句不要使用函数转换或计算，会导致无法使用索引 尽量不在数据库做运算，否则无法使用索引导致全表扫描 避免前缀模糊查询 用不了索引导致全表扫描 控制表单数据量 合理分表 单库不超过300-400个表 表字段少而精 字段上限控制在20-50个 效率优先 可以适当冗余 用好数据字段类型 tinyint int bigint 字符转化为数字 数字型更高效 查询更快 占用空间小 避免使用null 字段 难以进行查询优化 null列加索引，需要额外的空间按 含null复合索引无效 字符字段必须建前缀索引 ALTER TABLE messages_messagehistory ADD KEY (messagecontent(8)) 尽量不用外键 有额外开销 高并发容易死锁 大sql拆解成多条简单sql 缓存命中高 减少锁表时间 能用上更多的cpu 保持事务连接短小 与事务无关的操作放到事务外面 避免负向查询 如 not != &lt;&gt; !&lt; !&gt; not exists not in not like 减少count(*) 资源开销大 无需对结果去重时，用union all , union有去重开销 同数据类型的列值比较 数字对数字 字符对字符 字符列与数值类型比较 字符列转成数值，不会使用索引查询 两个表join的字段 数据类型要相同]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务]]></title>
    <url>%2F2018%2F10%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[未提交读（READ UNCOMMITTED）事务中的修改，即使没有提交，对其它事务也是可见的。使用查询语句不会加锁，可能会读到未提交的行（Dirty Read） 造成：脏读；不可重复读；幻影读 提交读（READ COMMITTED）一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read） 造成：不可重复读；幻影读 可重复读（REPEATABLE READ）保证在同一个事务中多次读取同样数据的结果是一样的。多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能发生幻读（Phantom Read） 造成：幻影读 可串行化（SERIALIZABLE）强制事务串行执行。InnoDB 隐式地将全部的查询语句加上共享锁，解决了幻读的问题； MySQLMySQL 中默认的事务隔离级别就是 REPEATABLE READ，它通过 Next-Key 锁也能够在某种程度上解决幻读的问题。MVCC 会产生幻读问题（更新时异常）在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Transaction</tag>
        <tag>Isolation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库事务]]></title>
    <url>%2F2018%2F10%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[原子性（Atomicity）事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 一致性（Consistency）数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 隔离性（Isolation）一个事务所做的修改在最终提交以前，对其它事务是不可见的。 持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[forward与redirect]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%2Fforward%E4%B8%8Eredirect%2F</url>
    <content type="text"><![CDATA[forward（转发）服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,因为这个跳转过程实在服务器实现的，并不是在客户端实现的所以客户端并不知道这个跳转动作，所以它的地址栏还是原来的地址. redirect（重定向）服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL. 区别转发是服务器行为，重定向是客户端行为，通过302状态码响应及对应新的location，发起第二次请求 转发页面和转发到的页面可以共享request里面的数据，重定向不能共享数据，过程中传输的信息会被丢失]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>forward</tag>
        <tag>redirect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Get与Post]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FGet%E4%B8%8EPost%2F</url>
    <content type="text"><![CDATA[HTTP定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE GETGET用于信息获取，而且应该是安全的和幂等的 GET请求的数据会附在URL之后 GET方式提交的数据最多只能是1024字节 POSTPOST表示可能修改变服务器上的资源的请求 POST把提交的数据则放置在是HTTP包的包体中 理论上POST没有限制，可传较大量的数据]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Get</tag>
        <tag>Post</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP2.0]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FHTTP2.0%2F</url>
    <content type="text"><![CDATA[HTTP2.0 的目的是通过支持请求与响应的多路复用来减少延迟，通过压缩HTTPS首部字段将协议开销降低，同时增加请求优先级和服务器端推送的支持。 二进制分帧层，是HTTP 2.0性能增强的核心。HTTP 1.x在应用层以纯文本的形式进行通信，而HTTP 2.0将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。这样，客户端和服务端都需要引入新的二进制编码和解码的机制。 二进制分帧层HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。 在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。 一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 服务端推送HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>HTTP2.0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FHTTPS%2F</url>
    <content type="text"><![CDATA[超文本传输协议HTTP 有以下安全性问题： 使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。 因此HTTP协议不适合传输一些敏感信息，比如信用卡号、密码等。 为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS。HTTPs 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。 通过使用 SSL，HTTPs 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 HTTP是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的SSL加密传输协议。 HTTP和HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 HTTP的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP协议安全。 HTTPS 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。 Nginx 配置 HTTPS 服务器]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Session]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FSession%2F</url>
    <content type="text"><![CDATA[除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 使用 Session 维护用户登录状态的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cookie]]></title>
    <url>%2F2018%2F10%2F26%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FCookie%2F</url>
    <content type="text"><![CDATA[HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。 如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户 用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 分类 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定一个特定的过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; JavaScript和Cookie通过 Document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。 123document.cookie = "yummy_cookie=choco";document.cookie = "tasty_cookie=strawberry";console.log(document.cookie); 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 Document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP状态码和首部]]></title>
    <url>%2F2018%2F10%2F24%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FHTTP%E7%8A%B6%E6%80%81%E7%A0%81%E5%92%8C%E9%A6%96%E9%83%A8%2F</url>
    <content type="text"><![CDATA[HTTP是一个应用层协议，也是一个无状态的协议，由请求和响应构成，是一个标准的客户端服务器模型。通常承载于TCP协议之上，有时也承载于TLS或SSL协议层之上，这个时候，就成了我们常说的HTTPS。 HTTP状态码服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。 状态码 类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK ：客户端请求成功 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：请求被拒绝。 404 Not Found ：请求的资源不存在 5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误。 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 HTTP首部通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息让服务端给每一个页面分配一个唯一的编号，通过编号来区分当前这个页面是否是最新的 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 Cache-ControlHTTP/1.1 通过 Cache-Control 首部字段来控制缓存。 Cache-Control: no-store指令规定不能对请求或响应的任何一部分进行缓存。 Cache-Control: no-cache指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效才将能使用该缓存对客户端的请求进行响应。 Cache-Control: max-age 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存；出现在响应报文中，表示缓存资源在缓存服务器中保存的时间。 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。 缓存验证需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源。可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。 Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 Not Modified 响应。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS域名解析]]></title>
    <url>%2F2018%2F10%2F24%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FDNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[DNS域名解析流程 用户输入域名按下回车 浏览器检查缓存中是否这个域名对应的解析过的IP地址 没有则继续 查找操作系统缓存 没有则继续 请求本地域名服务器LDNS 没有则继续 请求Root DNS Server，返回主域名服务器（gTLD server）地址 LDNS请求gTLD，gTLD返回Name Server域名服务器的地址 给LDNS LDNS查询Name Server 得到IP地址 LDNS返回IP地址给用户]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP协议]]></title>
    <url>%2F2018%2F10%2F24%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FTCP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[TCP通信原理对于TCP通信来说，每个Socket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的缓冲区和缓冲区填充状态。 接收缓冲区把数据缓存到内核，若应用进程一直没有调用Socket的read方法进行读取，那么该数据会一直被缓存在接收缓冲区内，不管进程是否读取Socket，对发送端发来的数据都会经过内核接收并缓存到Socket的内核接受缓冲区。 TCP报文段首部格式 序号seq：用于对字节流进行编号，例如序号为 101，表示第一个字节的编号为 101，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 201。 确认号ack：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认ACK：当 ACK=1 时确认号字段有效，否则无效。TCP 规定在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步SYN：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止FIN：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 三次握手 第一次握手：Client 向 Server 发送连接请求报文SYN=1，随机产生一个值seq= x给Server，Client 进入SYN_SENT状态，等待Server确认。 第二次握手：Server 收到连接请求报文，由标志位SYN=1知道Client请求建立连接,Server 向Client 发送连接确认报文SYN=1，ACK=1，seq为 x+1，同时随机产生一个值seq= y,Server进入SYN_RCVD状态 第三次握手：Client 收到 Server 的连接确认报文后,检查ACK是否为1，ack是否为x+1,如果正确则还要向 Server 发出确认，ack为 y+1,将标志位ACK置为1。Server检查ack是否为y+1,ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，开始传输数据。 SYN攻击时一种典型的DDOS攻击，就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。 三次握手的原因第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。客户端发送的连接请求如果在网络中延迟，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 四次挥手 第一次挥手：Client 发送连接释放报文，FIN=1，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。 第二次挥手：Server 收到FIN后之后发出确认，此时 TCP 属于半关闭状态，Server 能向 Client 发送数据但是 Client 不能向 Server 发送数据。发送一个ACK给Client，ack为u+1后进入CLOSE_WAIT状态。 第三次挥手：当Server 不再需要连接时，发送连接释放报文，FIN=1用来关闭Server到Client的数据传送，Server进入LAST_ACK状态 第四次挥手：Client 收到后FIN后进入 TIME-WAIT 状态，发出确认，等待 2 MSL（最大报文存活时间）后释放连接。Server 收到 Client 的确认后进入CLOSED状态 四次挥手的原因客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TIME_WAIT客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由 确保最后一个确认报文能够到达。如果Server 没收到Client 发送来的确认报文，那么就会重新发送连接释放请求报文，Client 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 超时重发当发送者向接收者发包后，如果过了一段时间(超时时间)依然没有收到消息，就当做本次包丢失，需要重新补发。并且如果一次性发了三个包，只要最后一个包确认收到之后就默认前面两个也收到了。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile语法]]></title>
    <url>%2F2018%2F10%2F24%2FDocker%2FDockerfile%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[12345678910111213FROM scratch # 制作baseimageFROM centos # 使用baseimageLABEL version="1.0" # 定义metadataRUN set -ex; # 执行命令并创建新的imagelayerWORKDIR demo # 创建目录并进入，默认根目录/testADD hello / # 将本地文件添加到里面ADD test.tar.gz / # 添加到根目录并解压COPY docker-entrypoint.sh /usr/local/bin/ # 添加文件，但不能解压ENV GOSU_VERSION 1.7 # 设置常量 使用$GOSU_VERSION引用常量VOLUME /var/lib/mysql # 存储EXPOSE 3306 33060 # 网络CMD ["mysqld"] # 设置容器启动后默认执行的命令和参数ENTRYPOINT ["docker-entrypoint.sh"] # 设置容器启动时运行的命令 docker-library里有官方收录的Dockerfile，可以作为参考 12docker build -t imagename path # 构建imagedocker run imagename # 运行]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker简介]]></title>
    <url>%2F2018%2F10%2F23%2FDocker%2FDocker%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Docker是一种虚拟化技术解决开发环境和生产环境环境一致的问题，通过Docker可以将程序运行的环境也纳入到版本控制中，解决一些项目交付时的麻烦。 底层技术支持Namespaces：通过Linux的Namespaces对不同的容器实现了隔离，包括进程、网络等信息。通过挂载点映射和宿主机的目录。 ControlGroups：隔离宿主机器上的物理资源，例如CPU、内存、磁盘I/O和网络带宽。 UnionFileSystems：container和image的分层。 image可以使用docker images ls命令查看本机的image 文件和metadata的集合 分层，每层都可以添加、改变、删除文件 image本身是只读的 获取方式 可以通过Dockerfile构建自己的image，使用docker build获取image 1234FROM ubuntu:15.04COPY . /appRUN make /appCMD python /app/app.py docker pull rabbitmq:management拉取image container可以使用docker container ls命令查看本机的container 通过image创建 类比面向对象：image是类，container是实例 负责运行 docker run -it xxx 可以进container里面进行一些操作]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS环境下安装Docker]]></title>
    <url>%2F2018%2F10%2F23%2FDocker%2FCentOS%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85Docker%2F</url>
    <content type="text"><![CDATA[官方安装文档 123456789101112131415yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engineyum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoyum install -y docker-cesystemctl start dockerdocker version 也可以使用阿里的镜像，将第三步指令替换成： 1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库锁]]></title>
    <url>%2F2018%2F10%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E9%94%81%2F</url>
    <content type="text"><![CDATA[排它锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。 在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 共享锁(S) 排他锁(X) 意向共享锁(IS) 意向排他锁(IX) 共享锁 兼容 冲突 兼容 冲突 排他锁 冲突 冲突 冲突 冲突 意向共享锁 兼容 冲突 兼容 兼容 意向排他锁 冲突 冲突 兼容 兼容 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容 三级封锁协议一级封锁协议：写-写；事务要修改数据时必须加 X 锁，直到事务结束才释放锁。可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议：写-读；在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题，因为如果一个事务在对数据进行修改，根据一级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议：读-写；在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题，因为读数据时，其它事务不能对数据加 X 锁，从而避免了在读的期间数据发生改变。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库引擎]]></title>
    <url>%2F2018%2F10%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[Innodb Myisam 存储文件 .frm表定义文件 ibd数据文件 .frm表定义文件 .myd数据文件 .myi索引文件 锁 表锁、行锁 表锁 事务 ACID 不支持 CURD 读、写 读多 count 扫表 专门存储的地方 索引结构 B+Tree B+Tree]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Innodb</tag>
        <tag>Myisam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BASE理论]]></title>
    <url>%2F2018%2F10%2F22%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FBASE%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[BASE理论是对CAP理论中一致性和可用性权衡的结果，如果无法做到强一致性，那就要采取合适的方法使系统达到最终一致性。传统的数据库系统要求强一致性(ACID)，BASE理论强调通过牺牲强一致性来达到可用性。在实际业务场景中，要结合业务对一致性的要求，将ACID和BASE结合起来使用。 基本可用(BasicallyAvailable)分布式系统在出现故障的时候，保证核心功能可用，允许损失部分可用性。 软状态(SoftState)允许系统中的数据存在中间状态，即系统不同节点的数据副本之间进行同步的过程存在时间延迟 最终一致性(EventuallyConsistent)系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>BASE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAP理论]]></title>
    <url>%2F2018%2F10%2F22%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FCAP%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[分布式系统不可能同时满足一致性(Consistency)、可用性(Availability)、分区容忍性(Partition Tolerance)，最多只能同时满足其中两项，这就是CAP理论。在分布式系统中分区容忍性必不可少，所以CAP理论实际上是要在可用性和一致性之间做取舍。 一致性多个数据副本能保持一致，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。如果系统的一个数据更新成功之后，所有用户都能够读取到最新的值，系统就被认为具有强一致性。 可用性分布式系统在面对各种异常时都可以提供正常服务，对于用户的每一个操作、请求总是能够在有限的时间内返回结果。 分区容忍性分布式系统在遇到任何网络分区故障的时候，仍然能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>CAP</tag>
      </tags>
  </entry>
</search>
